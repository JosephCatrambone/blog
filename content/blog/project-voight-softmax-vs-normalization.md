---
title: 'Project Voight: Softmax vs Normalization'
description: ""
published: 2015-03-08
redirect_from: 
            - https://www.josephcatrambone.com/?p=699
categories: "Programming"
hero: ../../../defaultHero.jpg
---
Adding softmax improved the network slightly. I'm thinking it might be excessive as a first layer, since it dilutes heavily the input vector. Let's compare softmax, normalization, and 'hardmax'.Softmax: (I.e., WF Y@b5-2N6-vPLX\*\\88532vXXfNl)Lb4CN:I think hardmax (really, just normalization in a different way) is the most compelling outcome. I'll have to toy with the network more and see what comes of it.
