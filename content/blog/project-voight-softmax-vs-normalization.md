+++
title = "Project Voight"
date = "2015-03-08"

[taxonomies]
tags=["Programming"]
+++

Adding softmax improved the network slightly. I'm thinking it might be excessive as a first layer, since it dilutes heavily the input vector. Let's compare softmax, normalization, and 'hardmax'.Softmax: (I.e., WF Y@b5-2N6-vPLX\*\\88532vXXfNl)Lb4CN:I think hardmax (really, just normalization in a different way) is the most compelling outcome. I'll have to toy with the network more and see what comes of it.
